{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "ExecuteTime": {
          "end_time": "2024-03-20T20:23:56.892203Z",
          "start_time": "2024-03-20T20:23:53.617395Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        },
        "id": "initial_id",
        "outputId": "47fbd523-bb9a-4eb8-f85d-40e8cef0a836"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2563d47-7612-43bd-b2fa-57c4e930d628\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b2563d47-7612-43bd-b2fa-57c4e930d628\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving supports.zip to supports.zip\n"
          ]
        }
      ],
      "source": [
        "# please upload data directory to Google drive\n",
        "# use Google Drive to load data\n",
        "from google.colab import drive, files\n",
        "import zipfile\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zipname = 'supports.zip'\n",
        "uploaded = files.upload()\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zipname, 'r') as zip_ref:\n",
        "  zip_ref.extractall()  # Extract all files to the current directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"requirements.txt\"\n",
        "!pip install torchinfo\n",
        "!pip install torcheval\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from models.DCNN import DCNN\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torchinfo import summary\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from Utils import create_dataloader, k_fold_cross_validation\n",
        "from torcheval.metrics import MulticlassAUROC, MulticlassF1Score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVNZuy_jxqbz",
        "outputId": "7ff9f7b7-1c6f-42cf-ce60-efbd39ae9d36"
      },
      "id": "MVNZuy_jxqbz",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anyio==4.3.0 (from -r requirements.txt (line 1))\n",
            "  Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
            "Requirement already satisfied: argon2-cffi==23.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (21.2.0)\n",
            "Collecting arrow==1.3.0 (from -r requirements.txt (line 4))\n",
            "  Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "Collecting asttokens==2.4.1 (from -r requirements.txt (line 5))\n",
            "  Using cached asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting async-lru==2.0.4 (from -r requirements.txt (line 6))\n",
            "  Using cached async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: attrs==23.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (23.2.0)\n",
            "Requirement already satisfied: audioread==3.0.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.0.1)\n",
            "Requirement already satisfied: Babel==2.14.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (2.14.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (4.12.3)\n",
            "Requirement already satisfied: bleach==6.1.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.1.0)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: cffi==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (3.3.2)\n",
            "Collecting colorama==0.4.6 (from -r requirements.txt (line 15))\n",
            "  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting comm==0.2.2 (from -r requirements.txt (line 16))\n",
            "  Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: contourpy==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (1.2.0)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.12.1)\n",
            "Collecting debugpy==1.8.1 (from -r requirements.txt (line 19))\n",
            "  Using cached debugpy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Collecting decorator==5.1.1 (from -r requirements.txt (line 20))\n",
            "  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (0.7.1)\n",
            "Requirement already satisfied: exceptiongroup==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.2.0)\n",
            "Collecting executing==2.0.1 (from -r requirements.txt (line 23))\n",
            "  Using cached executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fastjsonschema==2.19.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (2.19.1)\n",
            "Collecting filelock==3.9.0 (from -r requirements.txt (line 25))\n",
            "  Using cached filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: fonttools==4.50.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (4.50.0)\n",
            "Collecting fqdn==1.5.1 (from -r requirements.txt (line 27))\n",
            "  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting fsspec==2024.3.0 (from -r requirements.txt (line 28))\n",
            "  Using cached fsspec-2024.3.0-py3-none-any.whl (171 kB)\n",
            "Collecting h11==0.14.0 (from -r requirements.txt (line 29))\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting httpcore==1.0.4 (from -r requirements.txt (line 30))\n",
            "  Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "Collecting httpx==0.27.0 (from -r requirements.txt (line 31))\n",
            "  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "Collecting huggingface-hub==0.21.4 (from -r requirements.txt (line 32))\n",
            "  Using cached huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
            "Requirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (3.6)\n",
            "Collecting ipykernel==6.29.3 (from -r requirements.txt (line 34))\n",
            "  Using cached ipykernel-6.29.3-py3-none-any.whl (117 kB)\n",
            "Collecting ipython==8.22.2 (from -r requirements.txt (line 35))\n",
            "  Using cached ipython-8.22.2-py3-none-any.whl (811 kB)\n",
            "Collecting ipywidgets==8.1.2 (from -r requirements.txt (line 36))\n",
            "  Using cached ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "Collecting isoduration==20.11.0 (from -r requirements.txt (line 37))\n",
            "  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jedi==0.19.1 (from -r requirements.txt (line 38))\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: Jinja2==3.1.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (3.1.3)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (1.3.2)\n",
            "Collecting json5==0.9.24 (from -r requirements.txt (line 41))\n",
            "  Using cached json5-0.9.24-py3-none-any.whl (30 kB)\n",
            "Collecting jsonpointer==2.4 (from -r requirements.txt (line 42))\n",
            "  Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting jsonschema==4.21.1 (from -r requirements.txt (line 43))\n",
            "  Using cached jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "Requirement already satisfied: jsonschema-specifications==2023.12.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 44)) (2023.12.1)\n",
            "Collecting jupyter==1.0.0 (from -r requirements.txt (line 45))\n",
            "  Using cached jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting jupyter-console==6.6.3 (from -r requirements.txt (line 46))\n",
            "  Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Collecting jupyter-events==0.9.1 (from -r requirements.txt (line 47))\n",
            "  Using cached jupyter_events-0.9.1-py3-none-any.whl (18 kB)\n",
            "Collecting jupyter-lsp==2.2.4 (from -r requirements.txt (line 48))\n",
            "  Using cached jupyter_lsp-2.2.4-py3-none-any.whl (69 kB)\n",
            "Collecting jupyter_client==8.6.1 (from -r requirements.txt (line 49))\n",
            "  Using cached jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 50)) (5.7.2)\n",
            "Collecting jupyter_server==2.13.0 (from -r requirements.txt (line 51))\n",
            "  Using cached jupyter_server-2.13.0-py3-none-any.whl (383 kB)\n",
            "Collecting jupyter_server_terminals==0.5.3 (from -r requirements.txt (line 52))\n",
            "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Collecting jupyterlab==4.1.5 (from -r requirements.txt (line 53))\n",
            "  Using cached jupyterlab-4.1.5-py3-none-any.whl (11.4 MB)\n",
            "Requirement already satisfied: jupyterlab_pygments==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 54)) (0.3.0)\n",
            "Collecting jupyterlab_server==2.25.4 (from -r requirements.txt (line 55))\n",
            "  Using cached jupyterlab_server-2.25.4-py3-none-any.whl (58 kB)\n",
            "Requirement already satisfied: jupyterlab_widgets==3.0.10 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 56)) (3.0.10)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 57)) (1.4.5)\n",
            "Requirement already satisfied: lazy_loader==0.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 58)) (0.3)\n",
            "Requirement already satisfied: librosa==0.10.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 59)) (0.10.1)\n",
            "Collecting llvmlite==0.42.0 (from -r requirements.txt (line 60))\n",
            "  Using cached llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
            "Requirement already satisfied: MarkupSafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 61)) (2.1.5)\n",
            "Collecting matplotlib==3.8.3 (from -r requirements.txt (line 62))\n",
            "  Using cached matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 63)) (0.1.6)\n",
            "Collecting mistune==3.0.2 (from -r requirements.txt (line 64))\n",
            "  Using cached mistune-3.0.2-py3-none-any.whl (47 kB)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 65)) (1.3.0)\n",
            "Requirement already satisfied: msgpack==1.0.8 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 66)) (1.0.8)\n",
            "Requirement already satisfied: nbclient==0.10.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 67)) (0.10.0)\n",
            "Collecting nbconvert==7.16.2 (from -r requirements.txt (line 68))\n",
            "  Using cached nbconvert-7.16.2-py3-none-any.whl (257 kB)\n",
            "Requirement already satisfied: nbformat==5.10.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 69)) (5.10.3)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 70)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 71)) (3.2.1)\n",
            "Collecting notebook==7.1.2 (from -r requirements.txt (line 72))\n",
            "  Using cached notebook-7.1.2-py3-none-any.whl (5.0 MB)\n",
            "Requirement already satisfied: notebook_shim==0.2.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 73)) (0.2.4)\n",
            "Collecting numba==0.59.0 (from -r requirements.txt (line 74))\n",
            "  Using cached numba-0.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "Collecting numpy==1.26.4 (from -r requirements.txt (line 75))\n",
            "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Collecting overrides==7.7.0 (from -r requirements.txt (line 76))\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: packaging==24.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 77)) (24.0)\n",
            "Requirement already satisfied: pandocfilters==1.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 78)) (1.5.1)\n",
            "Requirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 79)) (0.8.3)\n",
            "Collecting pillow==10.2.0 (from -r requirements.txt (line 80))\n",
            "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "Requirement already satisfied: platformdirs==4.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 81)) (4.2.0)\n",
            "Requirement already satisfied: pooch==1.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 82)) (1.8.1)\n",
            "Requirement already satisfied: prometheus_client==0.20.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 83)) (0.20.0)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.43 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 84)) (3.0.43)\n",
            "Collecting psutil==5.9.8 (from -r requirements.txt (line 85))\n",
            "  Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "Collecting pure-eval==0.2.2 (from -r requirements.txt (line 86))\n",
            "  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pycparser==2.21 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 87)) (2.21)\n",
            "Collecting Pygments==2.17.2 (from -r requirements.txt (line 88))\n",
            "  Using cached pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "Requirement already satisfied: pyparsing==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 89)) (3.1.2)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r requirements.txt (line 90))\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Collecting python-json-logger==2.0.7 (from -r requirements.txt (line 91))\n",
            "  Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.36.0 Requires-Python >=3.6,<3.10; 0.37.0 Requires-Python >=3.7,<3.10; 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==306 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==306\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: torcheval in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# limit GPU usage (Can be ignored)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "51e7ee162c4d26f"
      },
      "id": "51e7ee162c4d26f"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Invalid type for fraction argument, must be `float`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8d9717c99cf3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_per_process_memory_fraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/cuda/memory.py\u001b[0m in \u001b[0;36mset_per_process_memory_fraction\u001b[0;34m(fraction, device)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfraction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid type for fraction argument, must be `float`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfraction\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfraction\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid fraction value: {fraction}. Allowed range: 0~1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid type for fraction argument, must be `float`"
          ]
        }
      ],
      "source": [
        "# torch.cuda.set_per_process_memory_fraction(0.8)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-20T20:23:57.430218Z",
          "start_time": "2024-03-20T20:23:56.893179Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "id": "6583ec646f0cdf76",
        "outputId": "33cc3000-ce83-455c-d2f9-450d0e2e4f49"
      },
      "id": "6583ec646f0cdf76",
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "51a5db70937b662"
      },
      "id": "51a5db70937b662"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finsh reading data\n"
          ]
        }
      ],
      "source": [
        "root = '/content/drive/MyDrive/Data/genres_original' # Change according path storing data\n",
        "genres = os.listdir(root)\n",
        "x = []\n",
        "y = []\n",
        "length = []\n",
        "sr = 16*1000\n",
        "for genre in genres:\n",
        "    genre_root = os.path.join(root, genre)\n",
        "    audios = os.listdir(genre_root)\n",
        "    for audio in audios:\n",
        "        audio_path = os.path.join(genre_root, audio)\n",
        "        signal, sr = librosa.load(audio_path, sr=sr)\n",
        "        x.append(signal)\n",
        "        length.append(len(signal))\n",
        "        y.append(genres.index(genre))\n",
        "min_length = min(length)\n",
        "print(\"finsh reading data\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-20T20:24:06.734363Z",
          "start_time": "2024-03-20T20:23:57.431242Z"
        },
        "id": "688fcddfa5166508",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5734de51-35e0-46a8-dd1e-a3b8d52eff53"
      },
      "id": "688fcddfa5166508",
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segment and Normalise"
      ],
      "metadata": {
        "collapsed": false,
        "id": "cb9b1d09933e8c"
      },
      "id": "cb9b1d09933e8c"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish segmentation and normalisation\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(x)):\n",
        "    x[i] = x[i][0:min_length]\n",
        "    x[i] = librosa.util.normalize(x[i])\n",
        "x = np.asarray(x)\n",
        "y = np.asarray(y)\n",
        "# print(x.shape,y.shape)\n",
        "seg_length = 59049\n",
        "frame_num = int(x.shape[1]/seg_length)\n",
        "preprocessed_x = x[:, :frame_num*seg_length].reshape(frame_num*x.shape[0],1,seg_length)\n",
        "preprocessed_y = (y.reshape(y.shape[0],1)*np.ones((y.shape[0],frame_num))).reshape(y.shape[0]*frame_num)\n",
        "# print(preprocessed_x.shape,preprocessed_y.shape)\n",
        "print(\"finish segmentation and normalisation\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-20T20:24:11.680958Z",
          "start_time": "2024-03-20T20:24:06.735336Z"
        },
        "id": "adde1dd7a93a75bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64b31c64-062f-4e13-954c-dbd77d0595b7"
      },
      "id": "adde1dd7a93a75bf",
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data"
      ],
      "metadata": {
        "collapsed": false,
        "id": "980160b9ea266574"
      },
      "id": "980160b9ea266574"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish splitting data\n"
          ]
        }
      ],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(preprocessed_x, preprocessed_y, test_size=0.2,\n",
        "                                                    stratify=preprocessed_y,shuffle=True)\n",
        "# k-fold cross validation\n",
        "k = 5\n",
        "xs_train, ys_train, xs_valid, ys_valid = k_fold_cross_validation(x_train,y_train,k)\n",
        "print(\"finish splitting data\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-20T20:24:13.400221Z",
          "start_time": "2024-03-20T20:24:11.682406Z"
        },
        "id": "9beb60e3ce30783e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258cdd96-7311-47d2-bcbd-61d77b034b40"
      },
      "id": "9beb60e3ce30783e",
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataloaders"
      ],
      "metadata": {
        "collapsed": false,
        "id": "4e3231aec7017b9d"
      },
      "id": "4e3231aec7017b9d"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish creating dataloaders\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64 # can be adjusted according to GPU memory size\n",
        "dataloaders_train = []\n",
        "dataloaders_valid = []\n",
        "for i in range(k):\n",
        "    dataloaders_train.append(create_dataloader(xs_train[i], ys_train[i], batch_size=batch_size))\n",
        "    dataloaders_valid.append(create_dataloader(xs_valid[i], ys_valid[i], batch_size=batch_size))\n",
        "dataloader_test = create_dataloader(x_test, y_test, batch_size=batch_size)\n",
        "print(\"finish creating dataloaders\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-20T20:24:17.735142Z",
          "start_time": "2024-03-20T20:24:13.401195Z"
        },
        "id": "96d7659a191d6c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346f3123-8126-4385-ad76-77aa7d24965c"
      },
      "id": "96d7659a191d6c43",
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Construction"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5d6cbe706ea9b080"
      },
      "id": "5d6cbe706ea9b080"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "DCNN                                     [64, 10]                  --\n",
              "├─ConLayer: 1-1                          [64, 128, 19683]          --\n",
              "│    └─Conv1d: 2-1                       [64, 128, 19683]          512\n",
              "│    └─BatchNorm1d: 2-2                  [64, 128, 19683]          256\n",
              "│    └─ReLU: 2-3                         [64, 128, 19683]          --\n",
              "├─Sequential: 1-2                        [64, 128, 2187]           --\n",
              "│    └─ConLayer: 2-4                     [64, 128, 6561]           --\n",
              "│    │    └─Conv1d: 3-1                  [64, 128, 19683]          49,280\n",
              "│    │    └─BatchNorm1d: 3-2             [64, 128, 19683]          256\n",
              "│    │    └─ReLU: 3-3                    [64, 128, 19683]          --\n",
              "│    │    └─MaxPool1d: 3-4               [64, 128, 6561]           --\n",
              "│    └─ConLayer: 2-5                     [64, 128, 2187]           --\n",
              "│    │    └─Conv1d: 3-5                  [64, 128, 6561]           49,280\n",
              "│    │    └─BatchNorm1d: 3-6             [64, 128, 6561]           256\n",
              "│    │    └─ReLU: 3-7                    [64, 128, 6561]           --\n",
              "│    │    └─MaxPool1d: 3-8               [64, 128, 2187]           --\n",
              "├─Sequential: 1-3                        [64, 256, 3]              --\n",
              "│    └─ConLayer: 2-6                     [64, 256, 729]            --\n",
              "│    │    └─Conv1d: 3-9                  [64, 256, 2187]           98,560\n",
              "│    │    └─BatchNorm1d: 3-10            [64, 256, 2187]           512\n",
              "│    │    └─ReLU: 3-11                   [64, 256, 2187]           --\n",
              "│    │    └─MaxPool1d: 3-12              [64, 256, 729]            --\n",
              "│    └─ConLayer: 2-7                     [64, 256, 243]            --\n",
              "│    │    └─Conv1d: 3-13                 [64, 256, 729]            196,864\n",
              "│    │    └─BatchNorm1d: 3-14            [64, 256, 729]            512\n",
              "│    │    └─ReLU: 3-15                   [64, 256, 729]            --\n",
              "│    │    └─MaxPool1d: 3-16              [64, 256, 243]            --\n",
              "│    └─ConLayer: 2-8                     [64, 256, 81]             --\n",
              "│    │    └─Conv1d: 3-17                 [64, 256, 243]            196,864\n",
              "│    │    └─BatchNorm1d: 3-18            [64, 256, 243]            512\n",
              "│    │    └─ReLU: 3-19                   [64, 256, 243]            --\n",
              "│    │    └─MaxPool1d: 3-20              [64, 256, 81]             --\n",
              "│    └─ConLayer: 2-9                     [64, 256, 27]             --\n",
              "│    │    └─Conv1d: 3-21                 [64, 256, 81]             196,864\n",
              "│    │    └─BatchNorm1d: 3-22            [64, 256, 81]             512\n",
              "│    │    └─ReLU: 3-23                   [64, 256, 81]             --\n",
              "│    │    └─MaxPool1d: 3-24              [64, 256, 27]             --\n",
              "│    └─ConLayer: 2-10                    [64, 256, 9]              --\n",
              "│    │    └─Conv1d: 3-25                 [64, 256, 27]             196,864\n",
              "│    │    └─BatchNorm1d: 3-26            [64, 256, 27]             512\n",
              "│    │    └─ReLU: 3-27                   [64, 256, 27]             --\n",
              "│    │    └─MaxPool1d: 3-28              [64, 256, 9]              --\n",
              "│    └─ConLayer: 2-11                    [64, 256, 3]              --\n",
              "│    │    └─Conv1d: 3-29                 [64, 256, 9]              196,864\n",
              "│    │    └─BatchNorm1d: 3-30            [64, 256, 9]              512\n",
              "│    │    └─ReLU: 3-31                   [64, 256, 9]              --\n",
              "│    │    └─MaxPool1d: 3-32              [64, 256, 3]              --\n",
              "├─ConLayer: 1-4                          [64, 512, 1]              --\n",
              "│    └─Conv1d: 2-12                      [64, 512, 3]              393,728\n",
              "│    └─BatchNorm1d: 2-13                 [64, 512, 3]              1,024\n",
              "│    └─ReLU: 2-14                        [64, 512, 3]              --\n",
              "│    └─MaxPool1d: 2-15                   [64, 512, 1]              --\n",
              "├─Sequential: 1-5                        [64, 512, 1]              --\n",
              "│    └─ConLayer: 2-16                    [64, 512, 1]              --\n",
              "│    │    └─Conv1d: 3-33                 [64, 512, 1]              262,656\n",
              "│    │    └─BatchNorm1d: 3-34            [64, 512, 1]              1,024\n",
              "│    │    └─ReLU: 3-35                   [64, 512, 1]              --\n",
              "│    └─Dropout: 2-17                     [64, 512, 1]              --\n",
              "├─Sequential: 1-6                        [64, 10]                  --\n",
              "│    └─Linear: 2-18                      [64, 10]                  5,130\n",
              "│    └─BatchNorm1d: 2-19                 [64, 10]                  20\n",
              "│    └─Sigmoid: 2-20                     [64, 10]                  --\n",
              "==========================================================================================\n",
              "Total params: 1,849,374\n",
              "Trainable params: 1,849,374\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 111.03\n",
              "==========================================================================================\n",
              "Input size (MB): 15.12\n",
              "Forward/backward pass size (MB): 6880.63\n",
              "Params size (MB): 7.40\n",
              "Estimated Total Size (MB): 6903.15\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = DCNN(10)\n",
        "model.cuda()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "opt = Adam(model.parameters(), lr=0.01)\n",
        "summary(model,[(64,1,seg_length)])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-20T20:24:18.938945Z",
          "start_time": "2024-03-20T20:24:17.737091Z"
        },
        "id": "586f84b92fed94cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3784086-339c-4437-f24e-3d54179628f3"
      },
      "id": "586f84b92fed94cc",
      "execution_count": 16
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ba0478e4d3367b5f"
      },
      "id": "ba0478e4d3367b5f"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------epoch  1 -------\n",
            "fold 1:\n",
            "train set loss: 2.0863609210191796\n",
            "train set accuracy: 0.373775839805603\n",
            "valid set loss: 2.067073633673401\n",
            "valid set accuracy: 0.3373231589794159\n",
            "fold 2:\n",
            "train set loss: 1.9408030193440933\n",
            "train set accuracy: 0.5171381831169128\n",
            "valid set loss: 1.8685509359486345\n",
            "valid set accuracy: 0.6028291583061218\n",
            "fold 3:\n",
            "train set loss: 1.8600755171106482\n",
            "train set accuracy: 0.5851469039916992\n",
            "valid set loss: 1.8864874109479886\n",
            "valid set accuracy: 0.47660499811172485\n",
            "fold 4:\n",
            "train set loss: 1.7979087117447299\n",
            "train set accuracy: 0.6441784501075745\n",
            "valid set loss: 1.7994746755853182\n",
            "valid set accuracy: 0.5560391545295715\n",
            "fold 5:\n",
            "train set loss: 1.7630908216823042\n",
            "train set accuracy: 0.6528835296630859\n",
            "valid set loss: 1.8177338426079401\n",
            "valid set accuracy: 0.5723612308502197\n",
            "-------epoch  2 -------\n",
            "fold 1:\n",
            "train set loss: 1.7297430650713135\n",
            "train set accuracy: 0.6964091062545776\n",
            "valid set loss: 1.8003314409214473\n",
            "valid set accuracy: 0.5799782276153564\n",
            "fold 2:\n",
            "train set loss: 1.7094388833113412\n",
            "train set accuracy: 0.7233405709266663\n",
            "valid set loss: 1.6935616380112475\n",
            "valid set accuracy: 0.7377583980560303\n",
            "fold 3:\n",
            "train set loss: 1.670864806860134\n",
            "train set accuracy: 0.7684983611106873\n",
            "valid set loss: 1.8212212326736783\n",
            "valid set accuracy: 0.5745375156402588\n",
            "fold 4:\n",
            "train set loss: 1.6461400010251117\n",
            "train set accuracy: 0.8011425137519836\n",
            "valid set loss: 1.6446117148435673\n",
            "valid set accuracy: 0.7704026103019714\n",
            "fold 5:\n",
            "train set loss: 1.6205600324989793\n",
            "train set accuracy: 0.8204569816589355\n",
            "valid set loss: 1.6846843710142847\n",
            "valid set accuracy: 0.7301414608955383\n",
            "-------epoch  3 -------\n",
            "fold 1:\n",
            "train set loss: 1.6252226332715338\n",
            "train set accuracy: 0.8185527324676514\n",
            "valid set loss: 1.681099901391321\n",
            "valid set accuracy: 0.6920565366744995\n",
            "fold 2:\n",
            "train set loss: 1.610119089727433\n",
            "train set accuracy: 0.8329706192016602\n",
            "valid set loss: 1.7072281576733594\n",
            "valid set accuracy: 0.683351457118988\n",
            "fold 3:\n",
            "train set loss: 1.5891868886542917\n",
            "train set accuracy: 0.8574537038803101\n",
            "valid set loss: 1.581468828744027\n",
            "valid set accuracy: 0.8628944158554077\n",
            "fold 4:\n",
            "train set loss: 1.5884217362409059\n",
            "train set accuracy: 0.8582698106765747\n",
            "valid set loss: 1.5803511906759784\n",
            "valid set accuracy: 0.871599555015564\n",
            "fold 5:\n",
            "train set loss: 1.5624021915668242\n",
            "train set accuracy: 0.8922742009162903\n",
            "valid set loss: 1.7536562157144224\n",
            "valid set accuracy: 0.6528835296630859\n",
            "-------epoch  4 -------\n",
            "fold 1:\n",
            "train set loss: 1.56163542172076\n",
            "train set accuracy: 0.8871055245399475\n",
            "valid set loss: 1.5594328379864533\n",
            "valid set accuracy: 0.8890097737312317\n",
            "fold 2:\n",
            "train set loss: 1.5574896085249328\n",
            "train set accuracy: 0.8949945569038391\n",
            "valid set loss: 1.5567770857805785\n",
            "valid set accuracy: 0.8933623433113098\n",
            "fold 3:\n",
            "train set loss: 1.5471887845339272\n",
            "train set accuracy: 0.8990750312805176\n",
            "valid set loss: 1.6029099878470967\n",
            "valid set accuracy: 0.8150163292884827\n",
            "fold 4:\n",
            "train set loss: 1.540465909456662\n",
            "train set accuracy: 0.9126768112182617\n",
            "valid set loss: 1.5977533309841052\n",
            "valid set accuracy: 0.8367790579795837\n",
            "fold 5:\n",
            "train set loss: 1.5274921747753487\n",
            "train set accuracy: 0.9360718131065369\n",
            "valid set loss: 1.5316247947846455\n",
            "valid set accuracy: 0.9227420687675476\n",
            "-------epoch  5 -------\n",
            "fold 1:\n",
            "train set loss: 1.5316687700408587\n",
            "train set accuracy: 0.9257344603538513\n",
            "valid set loss: 1.5586118618993168\n",
            "valid set accuracy: 0.8846572041511536\n",
            "fold 2:\n",
            "train set loss: 1.523506657083613\n",
            "train set accuracy: 0.9292709231376648\n",
            "valid set loss: 1.554743163474107\n",
            "valid set accuracy: 0.8792164921760559\n",
            "fold 3:\n",
            "train set loss: 1.521894971875553\n",
            "train set accuracy: 0.935799777507782\n",
            "valid set loss: 1.5914682380782117\n",
            "valid set accuracy: 0.8465723395347595\n",
            "fold 4:\n",
            "train set loss: 1.524871643271877\n",
            "train set accuracy: 0.9325353503227234\n",
            "valid set loss: 1.505809599868102\n",
            "valid set accuracy: 0.9564744234085083\n",
            "fold 5:\n",
            "train set loss: 1.518968257603111\n",
            "train set accuracy: 0.9371599555015564\n",
            "valid set loss: 1.573939596478127\n",
            "valid set accuracy: 0.8498367667198181\n",
            "-------epoch  6 -------\n",
            "fold 1:\n",
            "train set loss: 1.5142571631660917\n",
            "train set accuracy: 0.9458650350570679\n",
            "valid set loss: 1.5191018040473365\n",
            "valid set accuracy: 0.9314472079277039\n",
            "fold 2:\n",
            "train set loss: 1.5076379790269772\n",
            "train set accuracy: 0.9491294622421265\n",
            "valid set loss: 1.6135367061679329\n",
            "valid set accuracy: 0.817192554473877\n",
            "fold 3:\n",
            "train set loss: 1.5086155377482433\n",
            "train set accuracy: 0.9499455690383911\n",
            "valid set loss: 1.5371042361586345\n",
            "valid set accuracy: 0.9260064959526062\n",
            "fold 4:\n",
            "train set loss: 1.5071073726419526\n",
            "train set accuracy: 0.954842209815979\n",
            "valid set loss: 1.517734714379378\n",
            "valid set accuracy: 0.935799777507782\n",
            "fold 5:\n",
            "train set loss: 1.498557728055512\n",
            "train set accuracy: 0.9627311825752258\n",
            "valid set loss: 1.4961652240763552\n",
            "valid set accuracy: 0.9651795029640198\n",
            "-------epoch  7 -------\n",
            "fold 1:\n",
            "train set loss: 1.498660750435797\n",
            "train set accuracy: 0.9597387909889221\n",
            "valid set loss: 1.4883991024569407\n",
            "valid set accuracy: 0.9695320725440979\n",
            "fold 2:\n",
            "train set loss: 1.5026262710610723\n",
            "train set accuracy: 0.9610989689826965\n",
            "valid set loss: 1.4945844468925151\n",
            "valid set accuracy: 0.9662676453590393\n",
            "fold 3:\n",
            "train set loss: 1.4982360924418785\n",
            "train set accuracy: 0.9627311825752258\n",
            "valid set loss: 1.5464533797026458\n",
            "valid set accuracy: 0.8944504857063293\n",
            "fold 4:\n",
            "train set loss: 1.499337486266052\n",
            "train set accuracy: 0.9597387909889221\n",
            "valid set loss: 1.5253178586897576\n",
            "valid set accuracy: 0.9314472079277039\n",
            "fold 5:\n",
            "train set loss: 1.4980809146353937\n",
            "train set accuracy: 0.9632752537727356\n",
            "valid set loss: 1.4970173390827448\n",
            "valid set accuracy: 0.9662676453590393\n",
            "-------epoch  8 -------\n",
            "fold 1:\n",
            "train set loss: 1.494063781446679\n",
            "train set accuracy: 0.9681718945503235\n",
            "valid set loss: 1.4901967374232958\n",
            "valid set accuracy: 0.971708357334137\n",
            "fold 2:\n",
            "train set loss: 1.4954515659251333\n",
            "train set accuracy: 0.9657235741615295\n",
            "valid set loss: 1.5097121580121826\n",
            "valid set accuracy: 0.9390641450881958\n",
            "fold 3:\n",
            "train set loss: 1.4928136550303512\n",
            "train set accuracy: 0.9681718945503235\n",
            "valid set loss: 1.4854736440978191\n",
            "valid set accuracy: 0.9749727845191956\n",
            "fold 4:\n",
            "train set loss: 1.488544201435799\n",
            "train set accuracy: 0.9747007489204407\n",
            "valid set loss: 1.490351936632972\n",
            "valid set accuracy: 0.9684439301490784\n",
            "fold 5:\n",
            "train set loss: 1.490711587816639\n",
            "train set accuracy: 0.9703481793403625\n",
            "valid set loss: 1.5443575316077347\n",
            "valid set accuracy: 0.9009792804718018\n",
            "-------epoch  9 -------\n",
            "fold 1:\n",
            "train set loss: 1.4909737058251415\n",
            "train set accuracy: 0.9681718945503235\n",
            "valid set loss: 1.490326505101674\n",
            "valid set accuracy: 0.9619150757789612\n",
            "fold 2:\n",
            "train set loss: 1.491758258739675\n",
            "train set accuracy: 0.9668117165565491\n",
            "valid set loss: 1.4999735642050245\n",
            "valid set accuracy: 0.9597387909889221\n",
            "fold 3:\n",
            "train set loss: 1.4864046874580756\n",
            "train set accuracy: 0.973884642124176\n",
            "valid set loss: 1.485344111854545\n",
            "valid set accuracy: 0.9782372117042542\n",
            "fold 4:\n",
            "train set loss: 1.4845091238115247\n",
            "train set accuracy: 0.9776931405067444\n",
            "valid set loss: 1.4735603834521653\n",
            "valid set accuracy: 0.9858541488647461\n",
            "fold 5:\n",
            "train set loss: 1.4876831934682953\n",
            "train set accuracy: 0.9749727845191956\n",
            "valid set loss: 1.4960171316341944\n",
            "valid set accuracy: 0.9575625658035278\n",
            "-------epoch  10 -------\n",
            "fold 1:\n",
            "train set loss: 1.488345021262392\n",
            "train set accuracy: 0.9687159657478333\n",
            "valid set loss: 1.512701733587097\n",
            "valid set accuracy: 0.9412404298782349\n",
            "fold 2:\n",
            "train set loss: 1.4832985781222354\n",
            "train set accuracy: 0.9790533185005188\n",
            "valid set loss: 1.4925389302827587\n",
            "valid set accuracy: 0.9630032181739807\n",
            "fold 3:\n",
            "train set loss: 1.486129874892541\n",
            "train set accuracy: 0.9706202149391174\n",
            "valid set loss: 1.5093683346830333\n",
            "valid set accuracy: 0.9466811418533325\n",
            "fold 4:\n",
            "train set loss: 1.4831637445030585\n",
            "train set accuracy: 0.9787812829017639\n",
            "valid set loss: 1.4836824219167168\n",
            "valid set accuracy: 0.9684439301490784\n",
            "fold 5:\n",
            "train set loss: 1.479570006260545\n",
            "train set accuracy: 0.9817736148834229\n",
            "valid set loss: 1.4926443332167783\n",
            "valid set accuracy: 0.9695320725440979\n",
            "-------epoch  11 -------\n",
            "fold 1:\n",
            "train set loss: 1.4833839760770995\n",
            "train set accuracy: 0.9760609269142151\n",
            "valid set loss: 1.4732910450446592\n",
            "valid set accuracy: 0.9912948608398438\n",
            "fold 2:\n",
            "train set loss: 1.4802401574314354\n",
            "train set accuracy: 0.9825897216796875\n",
            "valid set loss: 1.4799175156083797\n",
            "valid set accuracy: 0.9793253540992737\n",
            "fold 3:\n",
            "train set loss: 1.4801430912349895\n",
            "train set accuracy: 0.9812295436859131\n",
            "valid set loss: 1.4766408393121\n",
            "valid set accuracy: 0.9847660064697266\n",
            "fold 4:\n",
            "train set loss: 1.4788549226567846\n",
            "train set accuracy: 0.981501579284668\n",
            "valid set loss: 1.476731632687192\n",
            "valid set accuracy: 0.9847660064697266\n",
            "fold 5:\n",
            "train set loss: 1.4987487929170877\n",
            "train set accuracy: 0.9542981386184692\n",
            "valid set loss: 1.4860516233983834\n",
            "valid set accuracy: 0.9695320725440979\n",
            "-------epoch  12 -------\n",
            "fold 1:\n",
            "train set loss: 1.4895323614819913\n",
            "train set accuracy: 0.9700761437416077\n",
            "valid set loss: 1.5078239722402362\n",
            "valid set accuracy: 0.9401522874832153\n",
            "fold 2:\n",
            "train set loss: 1.480448878369212\n",
            "train set accuracy: 0.9823176860809326\n",
            "valid set loss: 1.4807962009255593\n",
            "valid set accuracy: 0.9782372117042542\n",
            "fold 3:\n",
            "train set loss: 1.4775613022317564\n",
            "train set accuracy: 0.9844939708709717\n",
            "valid set loss: 1.4766044726958083\n",
            "valid set accuracy: 0.9825897216796875\n",
            "fold 4:\n",
            "train set loss: 1.474566987082281\n",
            "train set accuracy: 0.9872143268585205\n",
            "valid set loss: 1.4683244770577215\n",
            "valid set accuracy: 0.9945592880249023\n",
            "fold 5:\n",
            "train set loss: 1.478648864405718\n",
            "train set accuracy: 0.9812295436859131\n",
            "valid set loss: 1.4929257991913223\n",
            "valid set accuracy: 0.9597387909889221\n",
            "-------epoch  13 -------\n",
            "fold 1:\n",
            "train set loss: 1.4822036392411158\n",
            "train set accuracy: 0.9782372117042542\n",
            "valid set loss: 1.4804383124568388\n",
            "valid set accuracy: 0.9793253540992737\n",
            "fold 2:\n",
            "train set loss: 1.4827812729774283\n",
            "train set accuracy: 0.9776931405067444\n",
            "valid set loss: 1.4807943064188411\n",
            "valid set accuracy: 0.9782372117042542\n",
            "fold 3:\n",
            "train set loss: 1.4779881425728865\n",
            "train set accuracy: 0.9812295436859131\n",
            "valid set loss: 1.5151679504164155\n",
            "valid set accuracy: 0.937976062297821\n",
            "fold 4:\n",
            "train set loss: 1.4785317073579192\n",
            "train set accuracy: 0.9817736148834229\n",
            "valid set loss: 1.4706279362376549\n",
            "valid set accuracy: 0.9945592880249023\n",
            "fold 5:\n",
            "train set loss: 1.4873787752302998\n",
            "train set accuracy: 0.9703481793403625\n",
            "valid set loss: 1.506256900492638\n",
            "valid set accuracy: 0.9390641450881958\n",
            "-------epoch  14 -------\n",
            "fold 1:\n",
            "train set loss: 1.4891502586101162\n",
            "train set accuracy: 0.9649074673652649\n",
            "valid set loss: 1.4763070983129176\n",
            "valid set accuracy: 0.9847660064697266\n",
            "fold 2:\n",
            "train set loss: 1.4787937701072735\n",
            "train set accuracy: 0.981501579284668\n",
            "valid set loss: 1.481953710414899\n",
            "valid set accuracy: 0.9782372117042542\n",
            "fold 3:\n",
            "train set loss: 1.482526819386861\n",
            "train set accuracy: 0.9752448201179504\n",
            "valid set loss: 1.4909290062330494\n",
            "valid set accuracy: 0.9619150757789612\n",
            "fold 4:\n",
            "train set loss: 1.4836154111191808\n",
            "train set accuracy: 0.973884642124176\n",
            "valid set loss: 1.4993395766443993\n",
            "valid set accuracy: 0.9466811418533325\n",
            "fold 5:\n",
            "train set loss: 1.4758459301067515\n",
            "train set accuracy: 0.9853100776672363\n",
            "valid set loss: 1.4717270663824902\n",
            "valid set accuracy: 0.9902067184448242\n",
            "-------epoch  15 -------\n",
            "fold 1:\n",
            "train set loss: 1.4794363278948315\n",
            "train set accuracy: 0.9774211049079895\n",
            "valid set loss: 1.5161658940559113\n",
            "valid set accuracy: 0.9303590655326843\n",
            "fold 2:\n",
            "train set loss: 1.4821191400905689\n",
            "train set accuracy: 0.9768770337104797\n",
            "valid set loss: 1.4718357163751994\n",
            "valid set accuracy: 0.9869422912597656\n",
            "fold 3:\n",
            "train set loss: 1.4739944386144976\n",
            "train set accuracy: 0.9863982200622559\n",
            "valid set loss: 1.4698040922526048\n",
            "valid set accuracy: 0.9934711456298828\n",
            "fold 4:\n",
            "train set loss: 1.4768225954717857\n",
            "train set accuracy: 0.9834058284759521\n",
            "valid set loss: 1.538313568740986\n",
            "valid set accuracy: 0.9009792804718018\n",
            "fold 5:\n",
            "train set loss: 1.4753193459650897\n",
            "train set accuracy: 0.9877583980560303\n",
            "valid set loss: 1.4695322957210104\n",
            "valid set accuracy: 0.9912948608398438\n",
            "finish training\n"
          ]
        }
      ],
      "source": [
        "for i in range(15):\n",
        "    print(\"-------epoch  {} -------\".format(i + 1))\n",
        "    for j in range(k):\n",
        "        print(f'fold {j+1}:')\n",
        "        loss_train = 0\n",
        "        accuracy_train = 0\n",
        "        train_size = 0\n",
        "        for batch_idx, (data, target) in enumerate(dataloaders_train[j]):\n",
        "            model.train()\n",
        "            output = model(data)\n",
        "            loss = loss_function(output, target)\n",
        "            opt.zero_grad()\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            loss_train += loss.item()*len(data)\n",
        "            accuracy = (output.argmax(1) == target).sum()\n",
        "            accuracy_train += accuracy\n",
        "            train_size += len(data)\n",
        "        print(\"train set loss: {}\".format(loss_train/train_size))\n",
        "        print(\"train set accuracy: {}\".format(accuracy_train /train_size))\n",
        "\n",
        "        loss_valid = 0\n",
        "        accuracy_valid = 0\n",
        "        valid_size = 0\n",
        "        for batch_idx, (data, target) in enumerate(dataloaders_valid[j]):\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = model(data)\n",
        "                loss = loss_function(output, target)\n",
        "                loss_valid += loss.item()*len(data)\n",
        "                accuracy = (output.argmax(1) == target).sum()\n",
        "                accuracy_valid += accuracy\n",
        "                valid_size += len(data)\n",
        "        print(\"valid set loss: {}\".format(loss_valid/valid_size))\n",
        "        print(\"valid set accuracy: {}\".format(accuracy_valid/valid_size))\n",
        "print(\"finish training\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-20T20:47:34.153112Z",
          "start_time": "2024-03-20T20:24:18.939968Z"
        },
        "id": "156ba58e4ff24277",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "703d567b-cec0-4dac-f866-2d465331e982"
      },
      "id": "156ba58e4ff24277",
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "collapsed": false,
        "id": "9fd11d0b594c7140"
      },
      "id": "9fd11d0b594c7140"
    },
    {
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set loss: 1.5538323197393857\n",
            "test set accuracy: 0.8920800685882568\n",
            "test set AUC: 0.8870842456817627\n",
            "test set f1-score: 0.8920800685882568\n"
          ]
        }
      ],
      "source": [
        "loss_test = 0\n",
        "accuracy_test = 0\n",
        "AUC_test = 0\n",
        "f1_score_test = 0\n",
        "test_size = 0\n",
        "for batch_idx, (data, target) in enumerate(dataloader_test):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss_test += loss.item()*len(data)\n",
        "        accuracy = (output.argmax(1) == target).sum()\n",
        "        accuracy_test += accuracy\n",
        "        test_size += len(data)\n",
        "        auc = MulticlassAUROC(num_classes=10)\n",
        "        auc.update(output, target)\n",
        "        AUC_test += auc.compute()*len(data)\n",
        "        f1 = MulticlassF1Score(num_classes=10)\n",
        "        f1.update(output,target)\n",
        "        f1_score_test += f1.compute()*len(data)\n",
        "print(\"test set loss: {}\".format(loss_test/test_size))\n",
        "print(\"test set accuracy: {}\".format(accuracy_test/test_size))\n",
        "print(\"test set AUC: {}\".format(AUC_test/test_size))\n",
        "print(\"test set f1-score: {}\".format(f1_score_test/test_size))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-03-20T22:45:31.223051Z",
          "start_time": "2024-03-20T22:45:29.516398Z"
        },
        "id": "f65311f27441f0d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b8b30e4-3380-4c65-d88e-9c42ca1b3d3b"
      },
      "id": "f65311f27441f0d6",
      "execution_count": 18
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}