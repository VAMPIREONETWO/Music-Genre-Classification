{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FCN"
      ],
      "metadata": {
        "id": "1i4VVxsV0E0k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "fYtcRGNtzSyJ",
        "outputId": "8808bcaf-cc26-4234-b31f-53b72fdf9f36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1e0846e6-0230-444b-8b28-5ffad7047e3f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1e0846e6-0230-444b-8b28-5ffad7047e3f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving requirements.txt to requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# please upload data directory to Google drive\n",
        "# use Google Drive to load data\n",
        "from google.colab import drive, files\n",
        "import zipfile\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "filename = 'requirements.txt'\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"./requirements.txt\"\n",
        "!pip install torchinfo\n",
        "!pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XObE5pT60JST",
        "outputId": "d460b82c-1981-43eb-c14a-c7505114de67"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anyio==4.3.0 (from -r ./requirements.txt (line 1))\n",
            "  Downloading anyio-4.3.0-py3-none-any.whl (85 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: argon2-cffi==23.1.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 2)) (23.1.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 3)) (21.2.0)\n",
            "Collecting arrow==1.3.0 (from -r ./requirements.txt (line 4))\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/66.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting asttokens==2.4.1 (from -r ./requirements.txt (line 5))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting async-lru==2.0.4 (from -r ./requirements.txt (line 6))\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: attrs==23.2.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 7)) (23.2.0)\n",
            "Requirement already satisfied: audioread==3.0.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 8)) (3.0.1)\n",
            "Requirement already satisfied: Babel==2.14.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 9)) (2.14.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.12.3 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 10)) (4.12.3)\n",
            "Requirement already satisfied: bleach==6.1.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 11)) (6.1.0)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 12)) (2024.2.2)\n",
            "Requirement already satisfied: cffi==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 13)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 14)) (3.3.2)\n",
            "Collecting colorama==0.4.6 (from -r ./requirements.txt (line 15))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting comm==0.2.2 (from -r ./requirements.txt (line 16))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: contourpy==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 17)) (1.2.0)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 18)) (0.12.1)\n",
            "Collecting debugpy==1.8.1 (from -r ./requirements.txt (line 19))\n",
            "  Downloading debugpy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator==5.1.1 (from -r ./requirements.txt (line 20))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: defusedxml==0.7.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 21)) (0.7.1)\n",
            "Requirement already satisfied: exceptiongroup==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 22)) (1.2.0)\n",
            "Collecting executing==2.0.1 (from -r ./requirements.txt (line 23))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: fastjsonschema==2.19.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 24)) (2.19.1)\n",
            "Collecting filelock==3.9.0 (from -r ./requirements.txt (line 25))\n",
            "  Downloading filelock-3.9.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: fonttools==4.50.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 26)) (4.50.0)\n",
            "Collecting fqdn==1.5.1 (from -r ./requirements.txt (line 27))\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting fsspec==2024.3.0 (from -r ./requirements.txt (line 28))\n",
            "  Downloading fsspec-2024.3.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.9/171.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11==0.14.0 (from -r ./requirements.txt (line 29))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.0.4 (from -r ./requirements.txt (line 30))\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx==0.27.0 (from -r ./requirements.txt (line 31))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.21.4 (from -r ./requirements.txt (line 32))\n",
            "  Downloading huggingface_hub-0.21.4-py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.4/346.4 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 33)) (3.6)\n",
            "Collecting ipykernel==6.29.3 (from -r ./requirements.txt (line 34))\n",
            "  Downloading ipykernel-6.29.3-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.1/117.1 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipython==8.22.2 (from -r ./requirements.txt (line 35))\n",
            "  Downloading ipython-8.22.2-py3-none-any.whl (811 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipywidgets==8.1.2 (from -r ./requirements.txt (line 36))\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isoduration==20.11.0 (from -r ./requirements.txt (line 37))\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Collecting jedi==0.19.1 (from -r ./requirements.txt (line 38))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2==3.1.3 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 39)) (3.1.3)\n",
            "Requirement already satisfied: joblib==1.3.2 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 40)) (1.3.2)\n",
            "Collecting json5==0.9.24 (from -r ./requirements.txt (line 41))\n",
            "  Downloading json5-0.9.24-py3-none-any.whl (30 kB)\n",
            "Collecting jsonpointer==2.4 (from -r ./requirements.txt (line 42))\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting jsonschema==4.21.1 (from -r ./requirements.txt (line 43))\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications==2023.12.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 44)) (2023.12.1)\n",
            "Collecting jupyter==1.0.0 (from -r ./requirements.txt (line 45))\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Collecting jupyter-console==6.6.3 (from -r ./requirements.txt (line 46))\n",
            "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
            "Collecting jupyter-events==0.9.1 (from -r ./requirements.txt (line 47))\n",
            "  Downloading jupyter_events-0.9.1-py3-none-any.whl (18 kB)\n",
            "Collecting jupyter-lsp==2.2.4 (from -r ./requirements.txt (line 48))\n",
            "  Downloading jupyter_lsp-2.2.4-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_client==8.6.1 (from -r ./requirements.txt (line 49))\n",
            "  Downloading jupyter_client-8.6.1-py3-none-any.whl (105 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter_core==5.7.2 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 50)) (5.7.2)\n",
            "Collecting jupyter_server==2.13.0 (from -r ./requirements.txt (line 51))\n",
            "  Downloading jupyter_server-2.13.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.2/383.2 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter_server_terminals==0.5.3 (from -r ./requirements.txt (line 52))\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Collecting jupyterlab==4.1.5 (from -r ./requirements.txt (line 53))\n",
            "  Downloading jupyterlab-4.1.5-py3-none-any.whl (11.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab_pygments==0.3.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 54)) (0.3.0)\n",
            "Collecting jupyterlab_server==2.25.4 (from -r ./requirements.txt (line 55))\n",
            "  Downloading jupyterlab_server-2.25.4-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyterlab_widgets==3.0.10 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 56)) (3.0.10)\n",
            "Requirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 57)) (1.4.5)\n",
            "Requirement already satisfied: lazy_loader==0.3 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 58)) (0.3)\n",
            "Requirement already satisfied: librosa==0.10.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 59)) (0.10.1)\n",
            "Collecting llvmlite==0.42.0 (from -r ./requirements.txt (line 60))\n",
            "  Downloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 61)) (2.1.5)\n",
            "Collecting matplotlib==3.8.3 (from -r ./requirements.txt (line 62))\n",
            "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 63)) (0.1.6)\n",
            "Collecting mistune==3.0.2 (from -r ./requirements.txt (line 64))\n",
            "  Downloading mistune-3.0.2-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 65)) (1.3.0)\n",
            "Requirement already satisfied: msgpack==1.0.8 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 66)) (1.0.8)\n",
            "Requirement already satisfied: nbclient==0.10.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 67)) (0.10.0)\n",
            "Collecting nbconvert==7.16.2 (from -r ./requirements.txt (line 68))\n",
            "  Downloading nbconvert-7.16.2-py3-none-any.whl (257 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.3/257.3 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nbformat==5.10.3 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 69)) (5.10.3)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 70)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 71)) (3.2.1)\n",
            "Collecting notebook==7.1.2 (from -r ./requirements.txt (line 72))\n",
            "  Downloading notebook-7.1.2-py3-none-any.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook_shim==0.2.4 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 73)) (0.2.4)\n",
            "Collecting numba==0.59.0 (from -r ./requirements.txt (line 74))\n",
            "  Downloading numba-0.59.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.26.4 (from -r ./requirements.txt (line 75))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting overrides==7.7.0 (from -r ./requirements.txt (line 76))\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: packaging==24.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 77)) (24.0)\n",
            "Requirement already satisfied: pandocfilters==1.5.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 78)) (1.5.1)\n",
            "Requirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 79)) (0.8.3)\n",
            "Collecting pillow==10.2.0 (from -r ./requirements.txt (line 80))\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs==4.2.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 81)) (4.2.0)\n",
            "Requirement already satisfied: pooch==1.8.1 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 82)) (1.8.1)\n",
            "Requirement already satisfied: prometheus_client==0.20.0 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 83)) (0.20.0)\n",
            "Requirement already satisfied: prompt-toolkit==3.0.43 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 84)) (3.0.43)\n",
            "Collecting psutil==5.9.8 (from -r ./requirements.txt (line 85))\n",
            "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pure-eval==0.2.2 (from -r ./requirements.txt (line 86))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting pycparser==2.21 (from -r ./requirements.txt (line 87))\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pygments==2.17.2 (from -r ./requirements.txt (line 88))\n",
            "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r ./requirements.txt (line 89)) (3.1.2)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r ./requirements.txt (line 90))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-json-logger==2.0.7 (from -r ./requirements.txt (line 91))\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 0.36.0 Requires-Python >=3.6,<3.10; 0.37.0 Requires-Python >=3.7,<3.10; 0.52.0 Requires-Python >=3.6,<3.9; 0.52.0rc3 Requires-Python >=3.6,<3.9; 0.53.0 Requires-Python >=3.6,<3.10; 0.53.0rc1.post1 Requires-Python >=3.6,<3.10; 0.53.0rc2 Requires-Python >=3.6,<3.10; 0.53.0rc3 Requires-Python >=3.6,<3.10; 0.53.1 Requires-Python >=3.6,<3.10; 0.54.0 Requires-Python >=3.7,<3.10; 0.54.0rc2 Requires-Python >=3.7,<3.10; 0.54.0rc3 Requires-Python >=3.7,<3.10; 0.54.1 Requires-Python >=3.7,<3.10\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pywin32==306 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pywin32==306\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.10.0)\n",
            "Installing collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import (Module, Sequential, Conv2d, BatchNorm2d, ReLU, MaxPool2d,\n",
        "                      Linear, AdaptiveAvgPool2d, BatchNorm1d, Sigmoid, Dropout)\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from torchinfo import summary\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torcheval.metrics import MulticlassAUROC, MulticlassF1Score\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FfaltGWX0szS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add Methods"
      ],
      "metadata": {
        "id": "HgV2XX_g0vwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Util\n",
        "def create_dataloader(x, y, batch_size=64):\n",
        "    x = torch.tensor(x, dtype=torch.float).cuda()\n",
        "    y = torch.tensor(y, dtype=torch.long).cuda()\n",
        "    data = TensorDataset(x, y)\n",
        "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "def k_fold_cross_validation(x, y, k):\n",
        "    fold_size = x.shape[0] // k\n",
        "    xs_train = []\n",
        "    ys_train = []\n",
        "    xs_valid = []\n",
        "    ys_valid = []\n",
        "    for i in range(k - 1):\n",
        "        xs_valid.append(x[fold_size * i:fold_size * (i + 1)])\n",
        "        ys_valid.append(y[fold_size * i:fold_size * (i + 1)])\n",
        "        xs_train.append(np.concatenate([x[:fold_size * i], x[fold_size * (i + 1):]], axis=0))\n",
        "        ys_train.append(np.concatenate([y[:fold_size * i], y[fold_size * (i + 1):]], axis=0))\n",
        "    xs_valid.append(x[fold_size * (k - 1):])\n",
        "    ys_valid.append(y[fold_size * (k - 1):])\n",
        "    xs_train.append(x[:fold_size * (k - 1)])\n",
        "    ys_train.append(y[:fold_size * (k - 1)])\n",
        "    return xs_train, ys_train, xs_valid, ys_valid\n",
        "\n",
        "def train(model, loss_function, opt, dataloaders_train, dataloaders_valid, k, epoch=10):\n",
        "    epochs_loss = []\n",
        "    epochs_accuracy = []\n",
        "    for i in range(epoch):\n",
        "        print(\"-------epoch  {} -------\".format(i + 1))\n",
        "        epoch_loss = 0\n",
        "        epoch_accuracy = 0\n",
        "\n",
        "        for j in range(k):\n",
        "            print(f'fold {j + 1}:')\n",
        "\n",
        "            # train\n",
        "            loss_train = 0\n",
        "            accuracy_train = 0\n",
        "            train_size = 0\n",
        "            for batch_idx, (data, target) in enumerate(dataloaders_train[j]):\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "                model.train()\n",
        "                output = model(data)\n",
        "                loss = loss_function(output, target)\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "                data_size = len(data)\n",
        "                loss_train += loss.item() * data_size\n",
        "                accuracy_train += (output.argmax(1) == target).sum()\n",
        "                train_size += data_size\n",
        "            print(\"train set loss: {}\".format(loss_train / train_size))\n",
        "            print(\"train set accuracy: {}\".format(accuracy_train / train_size))\n",
        "\n",
        "            # valid\n",
        "            loss_valid = 0\n",
        "            accuracy_valid = 0\n",
        "            valid_size = 0\n",
        "            for batch_idx, (data, target) in enumerate(dataloaders_valid[j]):\n",
        "                data = data.cuda()\n",
        "                target = target.cuda()\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    output = model(data)\n",
        "                    loss = loss_function(output, target)\n",
        "                    data_size = len(data)\n",
        "                    loss_valid += loss.item() * data_size\n",
        "                    accuracy_valid += (output.argmax(1) == target).sum()\n",
        "                    valid_size += data_size\n",
        "            print(\"valid set loss: {}\".format(loss_valid / valid_size))\n",
        "            print(\"valid set accuracy: {}\".format(accuracy_valid / valid_size))\n",
        "            epoch_loss += loss_valid / valid_size\n",
        "            epoch_accuracy += accuracy_valid / valid_size\n",
        "        epoch_loss = round(epoch_loss / k, 3)\n",
        "        epoch_accuracy = round(float(epoch_accuracy) / k, 3)\n",
        "        print(f\"epoch loss: {epoch_loss}\")\n",
        "        print(f\"epoch accuracy: {epoch_accuracy}\")\n",
        "        epochs_loss.append(epoch_loss)\n",
        "        epochs_accuracy.append(epoch_accuracy)\n",
        "    return {\"loss\": epochs_loss, \"accuracy\": epochs_accuracy}\n",
        "\n",
        "\n",
        "def test(model, loss_function, dataloader_test):\n",
        "    loss_test = 0\n",
        "    accuracy_test = 0\n",
        "    AUC_test = 0\n",
        "    f1_score_test = 0\n",
        "    test_size = 0\n",
        "    for batch_idx, (data, target) in enumerate(dataloader_test):\n",
        "        data = data.cuda()\n",
        "        target = target.cuda()\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            output = model(data)\n",
        "            loss = loss_function(output, target)\n",
        "            loss_test += loss.item() * len(data)\n",
        "            accuracy_test += (output.argmax(1) == target).sum()\n",
        "            test_size += len(data)\n",
        "            auc = MulticlassAUROC(num_classes=10)\n",
        "            auc.update(output, target)\n",
        "            AUC_test += auc.compute() * len(data)\n",
        "            auc.reset()\n",
        "            f1 = MulticlassF1Score(num_classes=10)\n",
        "            f1.update(output, target)\n",
        "            f1_score_test += f1.compute() * len(data)\n",
        "            f1.reset()\n",
        "    loss = round(loss_test / test_size, 3)\n",
        "    accuracy = round(float(accuracy_test) / test_size,3)\n",
        "    AUC = round(float(AUC_test) / test_size, 3)\n",
        "    f1 = round(float(f1_score_test) / test_size,3)\n",
        "    print(f\"test set loss: {loss}\")\n",
        "    print(f\"test set accuracy: {accuracy}\")\n",
        "    print(f\"test set AUC: {AUC}\")\n",
        "    print(f\"test set f1-score: {f1}\")\n",
        "    return loss, accuracy, AUC, f1"
      ],
      "metadata": {
        "id": "huorwPg70xJg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Data"
      ],
      "metadata": {
        "id": "Y9OLPx1Y1qY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root = '/content/drive/MyDrive/why/genres_original' # Change according path storing data\n",
        "genres = os.listdir(root)\n",
        "x = []\n",
        "y = []\n",
        "length = []\n",
        "sr = 16*1000\n",
        "for genre in genres:\n",
        "    genre_root = os.path.join(root, genre)\n",
        "    audios = os.listdir(genre_root)\n",
        "    for audio in audios:\n",
        "        audio_path = os.path.join(genre_root, audio)\n",
        "        signal, sr = librosa.load(audio_path, sr=sr)\n",
        "        x.append(signal)\n",
        "        length.append(len(signal))\n",
        "        y.append(genres.index(genre))\n",
        "min_length = min(length)\n",
        "print(\"Finsh reading data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTThdYJU1n8b",
        "outputId": "c781b228-8404-4a4d-bd56-d6376838eb5e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finsh reading data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Segment and Normalise"
      ],
      "metadata": {
        "id": "YP5IOrVR14mq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_db = 80\n",
        "for i in range(len(x)):\n",
        "    signal = x[i][:min_length]\n",
        "    mel_spect = librosa.feature.melspectrogram(y=signal,sr=sr,n_fft=1024) # convert signals to mel spectrogram\n",
        "    mel_spect = librosa.power_to_db(mel_spect, ref=np.max, top_db=top_db) # log compression\n",
        "    x[i] = mel_spect/-top_db # normalisation\n",
        "print(\"finish conversion and compression\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc4T3FeE1n52",
        "outputId": "b671c0ca-1395-4fa0-92fc-92a137316df8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish conversion and compression\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split Data"
      ],
      "metadata": {
        "id": "CyOtbiN42Udu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.asarray(x)\n",
        "x = x.transpose((0,2,1))\n",
        "x = x.reshape(x.shape[0],1,x.shape[1],x.shape[2])\n",
        "y = np.asarray(y)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCSvDGpa1n3d",
        "outputId": "6a3aa191-1031-4399-f919-13c5877ace87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 1, 936, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2,\n",
        "                                                    stratify=y,shuffle=True)\n",
        "# k-fold cross validation\n",
        "k = 5\n",
        "xs_train, ys_train, xs_valid, ys_valid = k_fold_cross_validation(x_train,y_train,k)\n",
        "print(\"finish splitting data\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxdJ1NQj1n1W",
        "outputId": "61202180-b282-4f99-a83a-60fe5abd21dd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish splitting data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Dataloaders"
      ],
      "metadata": {
        "id": "ckQYoxJ_2cBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "dataloaders_train = []\n",
        "dataloaders_valid = []\n",
        "for i in range(k):\n",
        "    dataloaders_train.append(create_dataloader(xs_train[i], ys_train[i], batch_size=batch_size))\n",
        "    dataloaders_valid.append(create_dataloader(xs_valid[i], ys_valid[i], batch_size=batch_size))\n",
        "dataloader_test = create_dataloader(x_test, y_test, batch_size=batch_size)\n",
        "print(\"finish creating dataloaders\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAY0T_hf1nzD",
        "outputId": "5de427a7-156b-4eaa-c4ef-2985f46805fe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finish creating dataloaders\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FCN Model"
      ],
      "metadata": {
        "id": "uIt1LuGb29f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_filters, out_filters, stride=1):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn = nn.BatchNorm2d(out_filters)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class FCN7(nn.Module):\n",
        "    def __init__(self, class_num, pre_filter_size=7, in_channels=3):\n",
        "        super(FCN7, self).__init__()\n",
        "\n",
        "        self.conv1 = ConvBlock(1, 128)\n",
        "        # self.mp1 = nn.MaxPool2d((2, 4))\n",
        "        self.mp1 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "\n",
        "        self.conv2 = ConvBlock(128, 256)\n",
        "        # self.mp2 = nn.MaxPool2d((2, 4))\n",
        "        self.mp2 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "        self.conv3 = ConvBlock(256, 512)\n",
        "        # self.mp3 = nn.MaxPool2d((2, 4))\n",
        "        self.mp3 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "        self.conv4 = ConvBlock(512, 1024)\n",
        "        # self.mp4 = nn.MaxPool2d((3, 5))\n",
        "        self.mp4 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "        self.conv5 = ConvBlock(1024, 2048)\n",
        "        # self.mp5 = nn.MaxPool2d((4, 4))\n",
        "        self.mp5 = nn.MaxPool2d((2, 2))\n",
        "\n",
        "\n",
        "        self.conv6 = nn.Conv2d(2048, 1024, kernel_size=1) # 1x1 convolutions\n",
        "        self.conv7 = nn.Conv2d(1024, 1024, kernel_size=1) # additional 1x1 convolution as per FCN-7\n",
        "\n",
        "\n",
        "        self.avg_pool = AdaptiveAvgPool2d((1,1))\n",
        "\n",
        "        # Fully connected layer with batch normalization and sigmoid activation\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(1024, class_num),\n",
        "            nn.BatchNorm1d(class_num),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mp1(self.conv1(x))\n",
        "        print(\"After layer 1 & mp1:\", x.shape)\n",
        "        x = self.mp2(self.conv2(x))\n",
        "        print(\"After layer 2 & mp2:\", x.shape)\n",
        "        x = self.mp3(self.conv3(x))\n",
        "        print(\"After layer 3 & mp3:\", x.shape)\n",
        "        x = self.mp4(self.conv4(x))\n",
        "        print(\"After layer 4 & mp4:\", x.shape)\n",
        "        x = self.mp5(self.conv5(x))\n",
        "        print(\"After layer 5 & mp5:\", x.shape)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.conv7(x)\n",
        "        x = self.avg_pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        print(\"Shape before FC layer:\", x.shape)\n",
        "\n",
        "        # Apply the fully connected layer\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "AXnb4h8C1nw9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Construction"
      ],
      "metadata": {
        "id": "Mxqb732D4XRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x_tensor = torch.tensor(x).float().cuda()\n",
        "# y_tensor = torch.tensor(y).long().cuda()\n",
        "\n",
        "# input_shape = (1, x.shape[2],x.shape[3])\n",
        "class_num = 10\n",
        "model = FCN7(class_num=class_num).cuda()\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "opt = Adam(model.parameters(), lr=0.001)\n",
        "summary(model, input_size=[batch_size,1,x.shape[2],x.shape[3]])\n",
        "\n",
        "# # Initialize the model and move it to GPU\n",
        "# model = FCN7(class_num=10).cuda()\n",
        "\n",
        "# # Create a dummy input tensor that matches the input shape, including a batch dimension\n",
        "# dummy_input = torch.randn(1, 1, x.shape[2],x.shape[3]).cuda()\n",
        "# # Try a manual forward pass\n",
        "# try:\n",
        "#     model.eval()\n",
        "#     with torch.no_grad():\n",
        "#         dummy_output = model(dummy_input)\n",
        "#         print(\"Forward pass successful. Output shape:\", dummy_output.shape)\n",
        "# except Exception as e:\n",
        "#     print(\"Forward pass failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7er3woNS1nuY",
        "outputId": "b63d63f5-ebcd-4343-f1fd-1c94314fdc34"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After layer 1 & mp1: torch.Size([64, 128, 468, 64])\n",
            "After layer 2 & mp2: torch.Size([64, 256, 234, 32])\n",
            "After layer 3 & mp3: torch.Size([64, 512, 117, 16])\n",
            "After layer 4 & mp4: torch.Size([64, 1024, 58, 8])\n",
            "After layer 5 & mp5: torch.Size([64, 2048, 29, 4])\n",
            "Shape before FC layer: torch.Size([64, 1024])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "FCN7                                     [64, 10]                  --\n",
              "├─ConvBlock: 1-1                         [64, 128, 936, 128]       --\n",
              "│    └─Conv2d: 2-1                       [64, 128, 936, 128]       1,280\n",
              "│    └─BatchNorm2d: 2-2                  [64, 128, 936, 128]       256\n",
              "│    └─ReLU: 2-3                         [64, 128, 936, 128]       --\n",
              "├─MaxPool2d: 1-2                         [64, 128, 468, 64]        --\n",
              "├─ConvBlock: 1-3                         [64, 256, 468, 64]        --\n",
              "│    └─Conv2d: 2-4                       [64, 256, 468, 64]        295,168\n",
              "│    └─BatchNorm2d: 2-5                  [64, 256, 468, 64]        512\n",
              "│    └─ReLU: 2-6                         [64, 256, 468, 64]        --\n",
              "├─MaxPool2d: 1-4                         [64, 256, 234, 32]        --\n",
              "├─ConvBlock: 1-5                         [64, 512, 234, 32]        --\n",
              "│    └─Conv2d: 2-7                       [64, 512, 234, 32]        1,180,160\n",
              "│    └─BatchNorm2d: 2-8                  [64, 512, 234, 32]        1,024\n",
              "│    └─ReLU: 2-9                         [64, 512, 234, 32]        --\n",
              "├─MaxPool2d: 1-6                         [64, 512, 117, 16]        --\n",
              "├─ConvBlock: 1-7                         [64, 1024, 117, 16]       --\n",
              "│    └─Conv2d: 2-10                      [64, 1024, 117, 16]       4,719,616\n",
              "│    └─BatchNorm2d: 2-11                 [64, 1024, 117, 16]       2,048\n",
              "│    └─ReLU: 2-12                        [64, 1024, 117, 16]       --\n",
              "├─MaxPool2d: 1-8                         [64, 1024, 58, 8]         --\n",
              "├─ConvBlock: 1-9                         [64, 2048, 58, 8]         --\n",
              "│    └─Conv2d: 2-13                      [64, 2048, 58, 8]         18,876,416\n",
              "│    └─BatchNorm2d: 2-14                 [64, 2048, 58, 8]         4,096\n",
              "│    └─ReLU: 2-15                        [64, 2048, 58, 8]         --\n",
              "├─MaxPool2d: 1-10                        [64, 2048, 29, 4]         --\n",
              "├─Conv2d: 1-11                           [64, 1024, 29, 4]         2,098,176\n",
              "├─Conv2d: 1-12                           [64, 1024, 29, 4]         1,049,600\n",
              "├─AdaptiveAvgPool2d: 1-13                [64, 1024, 1, 1]          --\n",
              "├─Sequential: 1-14                       [64, 10]                  --\n",
              "│    └─Linear: 2-16                      [64, 10]                  10,250\n",
              "│    └─BatchNorm1d: 2-17                 [64, 10]                  20\n",
              "│    └─Sigmoid: 2-18                     [64, 10]                  --\n",
              "==========================================================================================\n",
              "Total params: 28,238,622\n",
              "Trainable params: 28,238,622\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (T): 2.29\n",
              "==========================================================================================\n",
              "Input size (MB): 30.67\n",
              "Forward/backward pass size (MB): 30538.74\n",
              "Params size (MB): 112.95\n",
              "Estimated Total Size (MB): 30682.36\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "tGayECcM2NN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 10\n",
        "history = train(model,loss_function,opt,dataloaders_train,dataloaders_valid,k,epoch=epoch)\n",
        "print(\"finish training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "i_r0r0vx1nsR",
        "outputId": "a2533c98-546b-45f6-f016-9abe9bcad436"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------epoch  1 -------\n",
            "fold 1:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacity of 14.75 GiB of which 2.75 GiB is free. Process 2121 has 11.99 GiB memory in use. Of the allocated memory 5.68 GiB is allocated by PyTorch, and 6.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3314e3801fd0>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloaders_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataloaders_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finish training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-fd1bb229c57c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_function, opt, dataloaders_train, dataloaders_valid, k, epoch)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-944187cf71c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"After layer 1 & mp1:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmp2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-944187cf71c0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \"\"\"\n\u001b[0;32m--> 175\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2482\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m     )\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 3.66 GiB. GPU 0 has a total capacity of 14.75 GiB of which 2.75 GiB is free. Process 2121 has 11.99 GiB memory in use. Of the allocated memory 5.68 GiB is allocated by PyTorch, and 6.18 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epoch),history['loss'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QJX5-vR91np4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(epoch), history['accuracy'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F9-9Os_j1nkN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "ysUvVXBk2U6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc, AUC, f1 = test(model,loss_function,dataloader_test)"
      ],
      "metadata": {
        "id": "03_x-vg-1nbB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}